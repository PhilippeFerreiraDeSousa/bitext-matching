{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "import Tools\n",
    "\n",
    "\n",
    "def expectation_maximization(foreign_word_dict,english_word_dict,foreign_sentences,english_sentences):\n",
    "    num_of_for_word = len(foreign_word_dict)\n",
    "    num_of_eng_word = len(english_word_dict)\n",
    "    # em algorithm\n",
    "    t_e_f_mat = np.full((len(foreign_word_dict), len(english_word_dict)), 1 / len(english_word_dict),dtype=float)\n",
    "    t_e_f_mat_prev = np.full((len(foreign_word_dict), len(english_word_dict)), 1,dtype=float)\n",
    "\n",
    "    cnt_iter = 0\n",
    "    while not Tools.is_converged(t_e_f_mat,t_e_f_mat_prev,cnt_iter) :\n",
    "        print(cnt_iter)\n",
    "        cnt_iter += 1\n",
    "        t_e_f_mat_prev = t_e_f_mat.copy()\n",
    "        count_e_f = np.full((len(foreign_word_dict), len(english_word_dict)), 0, dtype=float)\n",
    "        total_f = np.full((len(english_word_dict)),0, dtype=float)\n",
    "        print(\"sentece pairs\")\n",
    "        for idx_for, for_sen in enumerate(foreign_sentences): \n",
    "            #normalization\n",
    "            for_sen_words = for_sen.split(\" \")\n",
    "            s_total = np.full((len(for_sen_words)),0,dtype=float)\n",
    "            for idx_word in range(len(for_sen_words)): \n",
    "                for_word = for_sen_words[idx_word]\n",
    "                s_total[idx_word] = 0\n",
    "                eng_sen_words = english_sentences[idx_for].split(\" \")\n",
    "                for eng_word in eng_sen_words: \n",
    "                    idx_for_in_dict =foreign_word_dict[for_word]\n",
    "                    idx_eng_in_dict = english_word_dict[eng_word]\n",
    "                    s_total[idx_word] += t_e_f_mat[idx_for_in_dict][idx_eng_in_dict]\n",
    "           \n",
    "\n",
    "            #counts\n",
    "            for_sen_words = for_sen.split(\" \")\n",
    "            for idx_word in range(len(for_sen_words)): \n",
    "                for_word = for_sen_words[idx_word]\n",
    "                eng_sen_words = english_sentences[idx_for].split(\" \")\n",
    "                for eng_word in eng_sen_words:\n",
    "                    idx_for_in_dict =foreign_word_dict[for_word]\n",
    "                    idx_eng_in_dict = english_word_dict[eng_word]\n",
    "                    count_e_f[idx_for_in_dict][idx_eng_in_dict] += t_e_f_mat[idx_for_in_dict][idx_eng_in_dict] / s_total[idx_word]\n",
    "                    total_f[idx_eng_in_dict] += t_e_f_mat[idx_for_in_dict][idx_eng_in_dict] / s_total[idx_word]\n",
    "         \n",
    "        print(\"hey \")\n",
    "        print(str(datetime.now()))\n",
    "        #estimate probabilities\n",
    "        for eng_idx in  range(num_of_eng_word): \n",
    "            for for_idx in range(num_of_for_word): \n",
    "                if count_e_f[for_idx][eng_idx] != 0 :\n",
    "                    t_e_f_mat[for_idx][eng_idx] = count_e_f[for_idx][eng_idx] / total_f[eng_idx]\n",
    "   \n",
    "        print(\"finish \")\n",
    "        print(str(datetime.now()))\n",
    "\n",
    "\n",
    "    print(t_e_f_mat)\n",
    "    print(cnt_iter)\n",
    "\n",
    "    return t_e_f_mat\n",
    "\n",
    "\n",
    "def get_translation_prob(e,f,t,e_dict,f_dict):\n",
    "    const = Tools.const\n",
    "    l_e = len(e)\n",
    "    l_f = len(f)\n",
    "    res = const / math.pow((l_f+1),l_e)\n",
    "    for j in range(l_e):\n",
    "        e_word = e[j]\n",
    "        if e_word in e_dict:\n",
    "            e_j = e_dict[e_word]\n",
    "        else:\n",
    "            print(\"word '\"+ e_word +\"'not found in target language dictionary\")\n",
    "            continue\n",
    "            #return 0\n",
    "\n",
    "        sum = 0\n",
    "        for i in range(l_f):\n",
    "            f_word = f[i]\n",
    "\n",
    "            if f_word in f_dict:\n",
    "                f_i = f_dict[f_word]\n",
    "                sum += t[e_j][f_i]\n",
    "            else:\n",
    "                print(\"word '\" + f_word  +\"' not found in source language dictionary\")\n",
    "\n",
    "        res *= sum\n",
    "\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
