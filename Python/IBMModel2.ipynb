{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import Tools\n",
    "\n",
    "\n",
    "def train(t_e_f_mat, e_word_dict,f_word_dict,e_sentences,f_sentences,max_le,max_lf):\n",
    "    print(\"IBMModel2 Starts \" + str(datetime.now()))\n",
    "    a_i_le_lf_mat = np.zeros((max_lf, max_le, max_lf,max_le), dtype=float)\n",
    "\n",
    "    for lf in range(max_lf):\n",
    "        a_i_le_lf_mat[:,:,lf,:] = 1/(lf+1)\n",
    "\n",
    "    num_of_e_word = len(e_word_dict)\n",
    "    num_of_f_word = len(f_word_dict)\n",
    "\n",
    "    t_e_f_mat_prev = np.full((num_of_e_word, num_of_f_word), 1,dtype=float)\n",
    "    cnt_iter = 0\n",
    "\n",
    "    print(\"While starts \" + str(datetime.now()))\n",
    "    while not Tools.is_converged(t_e_f_mat,t_e_f_mat_prev,cnt_iter) :\n",
    "        print(cnt_iter)\n",
    "        cnt_iter += 1\n",
    "        t_e_f_mat_prev = t_e_f_mat.copy()\n",
    "        count_e_f = np.full((num_of_e_word, num_of_f_word), 0, dtype=float)\n",
    "        total_f = np.full((num_of_f_word),0, dtype=float)\n",
    "        count_a_i_le_lf = np.zeros((max_lf, max_le, max_lf,max_le), dtype=float)\n",
    "        total_a_j_le_lf = np.zeros((max_le,max_le,max_lf),dtype=float)\n",
    "\n",
    "        print(\"Sentence pair loop starts \" + str(datetime.now()))\n",
    "        for idx_e, e_sen in enumerate(e_sentences): #pairs of sentences (e,f) \n",
    "            #le = length(eng), lf = length(foreign)\n",
    "            e_sen_words = e_sen.split(\" \")\n",
    "            f_sen_words = f_sentences[idx_e].split(\" \")\n",
    "            l_e = len(e_sen_words)\n",
    "            l_f = len(f_sen_words)\n",
    "\n",
    "            #normalization\n",
    "            s_total = np.full((l_e),0,dtype=float)\n",
    "            for j in range(l_e): \n",
    "                s_total[j] = 0 #s-total(ej) = 0\n",
    "                e_word = e_sen_words[j]\n",
    "                for i in range(l_f): \n",
    "                    f_word = f_sen_words[i]\n",
    "                    e_j = e_word_dict[e_word]\n",
    "                    f_i = f_word_dict[f_word]\n",
    "                    s_total[j] += t_e_f_mat[e_j][f_i] * a_i_le_lf_mat[i][j][l_f-1][l_e-1] #s-total(ej) += t(ej|fi) ∗ a(i|j,le,lf)\n",
    "          \n",
    "\n",
    "            #collect counts\n",
    "            for j in range(l_e): \n",
    "                e_word = e_sen_words[j]\n",
    "                for i in range(l_f): \n",
    "                    f_word = f_sen_words[i]\n",
    "                    e_j = e_word_dict[e_word]\n",
    "                    f_i = f_word_dict[f_word]\n",
    "\n",
    "                    c = t_e_f_mat[e_j][f_i] * a_i_le_lf_mat[i][j][l_f-1][l_e-1] / s_total[j] #c = t(ej|fi) ∗ a(i|j,le,lf) / s-total(ej)\n",
    "                    count_e_f[e_j][f_i] += c #count(ej|fi) += c\n",
    "                    total_f[f_i] += c #total(fi) += c\n",
    "                    count_a_i_le_lf[i][j][l_f-1][l_e-1] += c #counta(i|j,le,lf) += c\n",
    "                    total_a_j_le_lf[j][l_e-1][l_f-1] += c #totala(j,le,lf) += c\n",
    "        \n",
    "\n",
    "        print(\"Estimate Probabilities starts \" + str(datetime.now()))\n",
    "        #estimate probabilities\n",
    "        t_e_f_mat = np.full((num_of_e_word, num_of_f_word), 0,dtype=float) #t(e|f) = 0 for all e,f\n",
    "        a_i_le_lf_mat = np.zeros((max_lf, max_le, max_lf,max_le), dtype=float) #a(i|j,le,lf) = 0 for all i,j,le,lf\n",
    "        for f_idx in  range(num_of_f_word):\n",
    "            for e_idx in range(num_of_e_word): \n",
    "                if count_e_f[e_idx][f_idx] != 0 :\n",
    "                    t_e_f_mat[e_idx][f_idx] = count_e_f[e_idx][f_idx] / total_f[f_idx]\n",
    "     \n",
    "        print(\"Estimating alignments starts \" + str(datetime.now()))\n",
    "        for i in range(max_lf):\n",
    "            for  j in range(max_le):\n",
    "                for le in range(max_le):\n",
    "                    for lf in range(max_lf):\n",
    "                        if count_a_i_le_lf[i][j][lf][le] != 0 :\n",
    "                            a_i_le_lf_mat[i][j][lf][le] = count_a_i_le_lf[i][j][lf][le] / total_a_j_le_lf[j][le][lf]\n",
    "\n",
    "    print(\"While loop ends print starts  \" + str(datetime.now()))\n",
    "\n",
    "    print(t_e_f_mat)\n",
    "    print(\"IBMModel2 Ends \" + str(datetime.now()))\n",
    "    return t_e_f_mat, a_i_le_lf_mat\n",
    "\n",
    "\n",
    "def get_translation_prob(e,f,t,a,e_dict,f_dict):\n",
    "    const = Tools.const\n",
    "    l_e = len(e)\n",
    "    l_f = len(f)\n",
    "    res = const\n",
    "    for j in range(l_e):\n",
    "        e_word = e[j]\n",
    "        if e_word in e_dict:\n",
    "            e_j = e_dict[e_word]\n",
    "        else:\n",
    "            print(Tools.O + \"word '\"+ e_word +\"not found in tgt language dictionary\" + Tools.BL)\n",
    "            continue\n",
    "            #return 0\n",
    "\n",
    "        sum = 0\n",
    "        for i in range(l_f):\n",
    "            f_word = f[i]\n",
    "\n",
    "            if f_word in f_dict:\n",
    "                f_i = f_dict[f_word]\n",
    "                sum += t[e_j][f_i]*a[i][j][l_f-1][l_e-1]\n",
    "            else:\n",
    "                print(Tools.B + \"word '\" + f_word  +\"' not found in src language dictionary\"+ Tools.BL)\n",
    "\n",
    "        res *= sum\n",
    "\n",
    "    if res == const:\n",
    "        return 0\n",
    "    return res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
