{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import IBMModel1\n",
    "import IBMModel2\n",
    "import Tools\n",
    "\n",
    "\n",
    "def get_tokens_of_sentence(sentence):\n",
    "    translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "    sentence = sentence.translate(translate_table)\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def sentence_tester(sentence):\n",
    "    try:\n",
    "        num_of_sentences = int(input(\"\\nHow many possible results you want to supply for sentece '\"+ sentence.strip() +\"': \\n\"))\n",
    "    except ValueError:\n",
    "        print (\"Not a number\")\n",
    "\n",
    "    possible_sentences = list()\n",
    "    for i in range(num_of_sentences):\n",
    "        input_sentence = input(\"Type possible sentence number \" + str((i+1)) + \" : \")\n",
    "        possible_sentences.append(input_sentence)\n",
    "\n",
    "    f_sentence = get_tokens_of_sentence(sentence)\n",
    "\n",
    "    max_score = -1\n",
    "    max_sentence = \"\"\n",
    "    for poss_sentence in possible_sentences:\n",
    "        e_sentence = get_tokens_of_sentence(poss_sentence)\n",
    "\n",
    "        if model_number == 1: #IBM Model 1\n",
    "            prob = IBMModel1.get_translation_prob(e_sentence,f_sentence,t_e_f,e_word_dict,f_word_dict)\n",
    "            print(Tools.P + \"probability for sentence '\" + poss_sentence + \"' is \" + str(prob) + Tools.BL)\n",
    "        elif model_number == 2: #IBM Model 2\n",
    "            prob = IBMModel2.get_translation_prob(e_sentence,f_sentence,t_e_f,a_i_j,e_word_dict,f_word_dict)\n",
    "            print(Tools.P + \"probability for sentence '\" + poss_sentence + \"' is \" + str(prob) + Tools.BL)\n",
    "        \n",
    "        if prob > max_score:\n",
    "            max_score = prob\n",
    "            max_sentence = poss_sentence\n",
    "\n",
    "    print(Tools.R + \"tranlation result is '\" + max_sentence +\"'  with probability : \" + str(max_score) + Tools.BL)\n",
    "\n",
    "def test(arg_model_number, is_sentence_translate,sentence_to_translate):\n",
    "    global t_e_f, a_i_j, n_fi_f, e_word_dict,f_word_dict,content_f,model_number\n",
    "\n",
    "    model_number = arg_model_number\n",
    "\n",
    "    if model_number == 1: #IBM Model 1\n",
    "        t_e_f = np.load('models/t_e_f_mat_model1.npy')\n",
    "    elif model_number == 2: #IBM Model 2\n",
    "        t_e_f = np.load('models/t_e_f_mat_model2.npy')\n",
    "        a_i_j = np.load('models/a_i_le_lf_mat_model2.npy')\n",
    "\n",
    "\n",
    "    e_word_dict = np.load(\"models/e_word_dict.npy\").item()\n",
    "    f_word_dict = np.load(\"models/f_word_dict.npy\").item()\n",
    "\n",
    "    if is_sentence_translate:\n",
    "        sentence_tester(sentence_to_translate)\n",
    "    else:\n",
    "        with open(\"Dictionary_files\\PP_en.txt\", encoding=\"utf8\") as f:\n",
    "                content_f = f.readlines()\n",
    "\n",
    "        new_content_f = list()\n",
    "\n",
    "        for sen_idx in range(len(content_f)):\n",
    "            cur_f_sen = content_f[sen_idx].split()\n",
    "            if len(cur_f_sen) < 11:\n",
    "                new_content_f.append(content_f[sen_idx])\n",
    "\n",
    "        content_f = new_content_f.copy()\n",
    "\n",
    "        for sentence in content_f [Tools.num_of_train_sample:(Tools.num_of_train_sample + Tools.num_of_test_sample)]:\n",
    "            sentence_tester(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
